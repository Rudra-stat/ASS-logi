{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tWhat is a classification problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s suppose you took a survey and noted the response of each person as satisfied, neutral or Not satisfied.\n",
    "Let’s map each category:\n",
    "\n",
    "Satisfied – 2\n",
    "\n",
    "Neutral – 1\n",
    "\n",
    "Not Satisfied – 0\n",
    "\n",
    "But this doesn’t mean that the gap between Not satisfied and Neutral is same as Neutral and satisfied. There is no mathematical significance of these mapping. We can also map the categories like:\n",
    "\n",
    "Satisfied – 0\n",
    "\n",
    "Neutral – 1\n",
    "\n",
    "Not Satisfied – 2\n",
    "\n",
    "It’s completely fine to choose the above mapping. If we apply linear regression to both the type of mappings, we will get different sets of predictions. Also, we can get prediction values like 1.2, 0.8, 2.3 etc. which makes no sense for categorical values. So, there is no normal method to convert qualitative data into quantitative data for use in linear regression.\n",
    "Although, for binary classification, i.e. when there only two categorical values, using the least square method can give decent results. Suppose we have two categories Black and White and we map them as follows:\n",
    "\n",
    "Black – 0\n",
    "\n",
    "White - 1 \n",
    "\n",
    "We can assign predicted values for both the categories such as Y> 0.5 goes to class white and vice versa.\n",
    "Although, there will be some predictions for which the value can be greater than 1 or less than 0 making them hard to classify in any class. Nevertheless, linear regression can work decently for binary classification but not that well for multi-class classification. \n",
    "Hence, we use classification methods for dealing with such problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tWhat is Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Logistic regression is one such regression algorithm which can be used for performing classification problems. It calculates the probability that a given value belongs to a specific class. If the probability is more than 50%, it assigns the value in that particular class else if the probability is less than 50%, the value is assigned to the other class. Therefore, we can say that logistic regression acts as a binary classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tWhy is the Sigmoid function used for Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)\tThe sigmoid function’s range is bounded between 0 and 1. Thus it’s useful in calculating the probability for the  Logistic function.\n",
    "2)\t It’s derivative is easy to calculate than other functions which is useful during gradient descent calculation.\n",
    "3)\tIt is a simple way of introducing non-linearity to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\tWhat is the cost function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cost Function**\n",
    "\n",
    "<img src=\"cf1.PNG\" width=\"300\">\n",
    "\n",
    "The cost function for the whole training set is given as :\n",
    "\n",
    "<img src=\"cf2.PNG\" width=\"300\">\n",
    "\n",
    "The values of parameters (θ) for which the cost function is minimum is calculated using the gradient descent (as discussed in the Linear Regression section) algorithm. The partial derivative for cost function is given as :\n",
    "\n",
    "<img src=\"derivative.PNG\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.\tWhat is multiple Logistic Function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Logistic Function\n",
    "\n",
    "We can generalise the simple logistic function for multiple features as:\n",
    "<img src=\"multi.PNG\" width=\"300\">\n",
    "\n",
    "And the logit function can be written as:\n",
    "\n",
    "<img src=\"logit.PNG\" width=\"300\">\n",
    "\n",
    "The coefficients are calculated the same we did for simple logistic function, by passing the above equation in the cost function.\n",
    "\n",
    "Just like we did in multilinear regression, we will check for correlation between different features for Multi logistic as well.\n",
    "\n",
    "We will see how we implement all the above concept through a practical example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.\tWhat is multilabel Logistic Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many times, there are classification problems where the number of classes is greater than 2. \n",
    "We can extend Logistic regression for multi-class classification. The logic is simple; we train our logistic model for each class and calculate the probability(hθx) that a specific feature belongs to that class. Once we have trained the model for all the classes, we predict a new value’s class by choosing that class for which the probability(hθx) is maximum.\n",
    "Although we have libraries that we can use to perform multinomial logistic regression, we rarely use logistic regression for classification problems where the number of classes is more than 2.\n",
    "There are many other classification models for such scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.\tHow does the Logistic Regression Algorithm learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Algorithm\n",
    "The learning algorithm is how we search the set of possible hypotheses (hypothesis space $\\mathcal{H}$) for the best parameterization (in this case the weight vector ${\\bf w}$). This search is an optimization problem looking for the hypothesis that optimizes an error measure.\n",
    "\n",
    "There is no sophisticted, closed-form solution like least-squares linear, so we will use gradient descent instead. Specifically we will use batch gradient descent which calculates the gradient from all data points in the data set.\n",
    "\n",
    "Luckily, our \"cross-entropy\" error measure is convex so there is only one minimum. Thus the minimum we arrive at is the global minimum.\n",
    "To learn we're going to minimize the following error measure using batch gradient descent.\n",
    "\n",
    "$$\n",
    "e(h({\\bf x}_n), y_n) = \\ln \\left( 1+e^{-y_n \\; {\\bf w}^T {\\bf x}_n} \\right) \\\\\n",
    "E_\\text{in}({\\bf w}) = \\frac{1}{N} \\sum_{n=1}^{N} e(h({\\bf x}_n), y_n) = \\frac{1}{N} \\sum_{n=1}^{N} \\ln \\left( 1+e^{-y_n \\; {\\bf w}^T {\\bf x}_n} \\right)\n",
    "$$\n",
    "\n",
    "We'll need the derivative of the point loss function and possibly some abuse of notation.\n",
    "\n",
    "$$\n",
    "\\frac{d}{d{\\bf w}} e(h({\\bf x}_n), y_n)\n",
    "= \\frac{-y_n \\; {\\bf x}_n \\; e^{-y_n {\\bf w}^T {\\bf x}_n}}{1 + e^{-y_n {\\bf w}^T {\\bf x}_n}}\n",
    "= -\\frac{y_n \\; {\\bf x}_n}{1 + e^{y_n {\\bf w}^T {\\bf x}_n}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.\tExplain the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "A typical confusion matrix looks like the figure shown.\n",
    "\n",
    "<img src=\"confusionMatrix.PNG\" width=\"300\">\n",
    "\n",
    "Where the terms have the meaning:\n",
    "\n",
    "\t__True Positive(TP):__ A result that was predicted as positive by the classification model and also is positive\n",
    "\n",
    "\t__True Negative(TN):__ A result that was predicted as negative by the classification model and also is negative\n",
    "\n",
    "\t__False Positive(FP):__ A result that was predicted as positive by the classification model but actually is negative\n",
    "\n",
    "\t__False Negative(FN):__ A result that was predicted as negative by the classification model but actually is positive.\n",
    "\n",
    "The Credibility of the model is based on how many correct predictions did the model do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.\tWhat is Accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "The mathematical formula is :\n",
    "\n",
    "   __Accuracy__= $ \\frac{ (TP+TN)}{(TP+TN+FP+FN)} $\n",
    "    \n",
    "Or, it can be said that it’s defined as the total number of correct classifications divided by the total number of classifications. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.\tWhy there is a need for other metrics if ‘accuracy’ is already present?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the model had a very high Accuracy but performed poorly in terms of Precision and Recall. So, necessarily _Accuracy_ is not the metric to use for evaluating the model in this case.\n",
    "\n",
    "Imagine a scenario, where the requirement was that the model recalled all the defaulters who did not pay back the loan. Suppose there were 10 such defaulters and to recall those 10 defaulters, and the model gave you 20 results out of which only the 10 are the actual defaulters. Now, the recall of the model is 100%, but the precision goes down to 50%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.\tWhat are Recall and Precision? How do they differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall or Sensitivity\n",
    "The mathematical formula is:\n",
    "\n",
    "   __Recall__= $ \\frac{ TP}{(TP+FN)} $\n",
    "\n",
    "Or, as the name suggests, it is a measure of: from the total number of positive results how many positives were correctly predicted by the model.\n",
    "\n",
    "It shows how relevant the model is, in terms of positive results only.\n",
    "\n",
    "Let’s suppose in the previous model, the model gave 50 correct predictions(TP) but failed to identify 200 cancer patients(FN). Recall in that case will be:\n",
    "\n",
    "Recall=$ \\frac {50}{(50+200)} $= 0.2 (The model was able to recall only 20% of the cancer patients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "\n",
    "Precision is a measure of amongst all the positive predictions, how many of them were actually positive. Mathematically,\n",
    "\n",
    "Precision=$ \\frac {TP}{(TP+FP)} $\n",
    "\n",
    "Let’s suppose in the previous example, the model identified 50 people as cancer patients(TP) but also raised a  false alarm for 100 patients(FP). Hence,\n",
    "\n",
    "Precision=$ \\frac {50}{(50+100)} $=0.33 (The model only has a precision of 33%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.\tHow does the tradeoff between recall and precision work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Trade-off?\n",
    "\n",
    "<img src=\"tradeoff.PNG\" width=\"300\">\n",
    "\n",
    "As observed from the graph, with an increase in the Recall, there is a drop in Precision of the model.\n",
    "\n",
    "So the question is - what to go for? Precision or Recall?\n",
    "\n",
    "Well, the answer is: it depends on the business requirement.\n",
    "\n",
    "For example, if you are predicting cancer, you need a 100 % recall. But suppose you are predicting whether a person is innocent or not, you need 100% precision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.\tExplain the F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous examples, it is clear that we need a metric that considers both Precision and Recall for evaluating a model. One such metric is the F1 score.\n",
    "\n",
    "F1 score is defined as the harmonic mean of Precision and Recall. \n",
    "\n",
    "The mathematical formula is:\n",
    "      F1 score= $ \\frac{2*((Precision*Recall)}{(Precision+Recall))} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.\tWhat is specificity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This represents how specific is the model while predicting the True Negatives.\n",
    "Mathematically,\n",
    "\n",
    "   Specificity=$ \\frac {TN}{(TN+FP)} $\n",
    "Or, it can be said that it quantifies the total number of negatives predicted by the model with respect to the total number of actual negative or non favorable outcomes.\n",
    "\n",
    "Similarly, False Positive rate can be defined as:  (1- specificity)\n",
    "Or,  $ \\frac {FP}{(TN+FP)} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.\tExplain the significance of ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve shows the trade-off between sensitivity (or TPR) and specificity (1 – FPR). Classifiers that give curves closer to the top-left corner indicate a better performance. As a baseline, a random classifier is expected to give points lying along the diagonal (FPR = TPR). The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test.\n",
    "\n",
    "Note that the ROC does not depend on the class distribution. This makes it useful for evaluating classifiers predicting rare events such as diseases or disasters. In contrast, evaluating performance using accuracy (TP +TN)/(TP + TN + FN + FP) would favor classifiers that always predict a negative outcome for rare events.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.\tWhat is AUC, and when is it used?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It helps us to choose the best model amongst the models for which we have plotted the ROC curves\n",
    "- The best model is the one which encompasses the maximum area under it.\n",
    "- In the adjacent diagram, amongst the two curves, the model that resulted in the red one should be chosen as it clearly covers more area than the blue one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.\tExplain the steps for Heroku deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment to Heroku:\n",
    "\n",
    "* After installing the Heroku CLI, Open a command prompt window and navigate to your project folder.\n",
    "* Type the command **heroku login** to login to your heroku account.\n",
    "* After logging in to Heroku, enter the command **heroku create** to create a heroku app. It will give you the URL of your Heroku app after successful creation. Or alternatively, you can go to the heroku website and create an app directly.\n",
    "* Before deploying the code to the Heroku cloud, we need to commit the changes to the git repository.\n",
    "* Type the command **git init** to initialize a local git repository.\n",
    "* Enter the command **git status** to see the uncommitted changes.\n",
    "* Enter the command **git add .** to add the uncommitted changes to the local repository.\n",
    "* Enter the command **git commit -am \"make it better\"** to commit the changes to the local repository.\n",
    "* Enter the command **git push heroku master** to push the code to the heroku cloud.\n",
    "* After deployment, heroku gives you the URL to hit the web API.\n",
    "* Once your application is deployed successfully, enter the command **heroku logs --tail** to see the logs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.\tWhat difficulties did you face while deploying to Heroku?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No defficulties face during deploying to Heroku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
